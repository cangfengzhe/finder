{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获得 id\n",
    "# http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=%s' % term_name\n",
    "\n",
    "# http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term=cancer&retstart=3182080&retmax=100\n",
    "# http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pmc&id=212403,4584127\n",
    "\n",
    "from common import *\n",
    "from lxml.etree import *\n",
    "import lxml.etree\n",
    "import math\n",
    "import re\n",
    "import pymysql\n",
    "\n",
    "\n",
    "\n",
    "def esearch(term, retstart, retmax, db='pubmed'):\n",
    "    '''\n",
    "    根据 term 查找数据库, 返回 xml\n",
    "    :param term: 搜索的条目\n",
    "    :param retstart: 起始位置\n",
    "    :param retmax:  长度\n",
    "    :param db: 数据库, 默认为pubmed\n",
    "    :return: xml\n",
    "    '''\n",
    "    term = urllib.parse.quote(term.encode('utf-8', 'replace'))\n",
    "    # urllib.parse.quote(url.encode('utf-8', 'replace'))\n",
    "    str_url = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=%s&term=%s&retstart=%d&retmax=%d' \\\n",
    "              % (db, term, retstart, retmax)\n",
    "    request = urllib.request.Request(str_url)\n",
    "    xml = urllib.request.urlopen(request).read()\n",
    "    # xml = open_url(str_url, encode='utf-8')\n",
    "    root = lxml.etree.XML(xml)\n",
    "    return root\n",
    "\n",
    "\n",
    "def get_id(term, retstart, retmax, db='pubmed'):\n",
    "    '''\n",
    "    返回处理后得到的id\n",
    "    :param term:  搜索term\n",
    "    :param retstart:\n",
    "    :param retmax:\n",
    "    :param db:\n",
    "    :return: 返回id列表\n",
    "    '''\n",
    "    root = esearch(term, retstart, retmax, db)\n",
    "    id_list = root.xpath('IdList/Id')\n",
    "    ids = [id.text for id in id_list]\n",
    "    return ids\n",
    "\n",
    "\n",
    "def get_id_count(term, db='pubmed'):\n",
    "    '''\n",
    "    得到该 term 下的文章数目\n",
    "    :param term:\n",
    "    :param db:\n",
    "    :return:\n",
    "    '''\n",
    "    root = esearch(term, 1, 1, db)\n",
    "    # print(root.tostring())\n",
    "    count = root.xpath('Count')[0].text\n",
    "    return count\n",
    "\n",
    "\n",
    "def query_id(term, retmax=100, db='pubmed'):\n",
    "    '''\n",
    "    核心函数\n",
    "    :param term:\n",
    "    :param retmax: 每页显示的id数目\n",
    "    :param db:\n",
    "    :return:\n",
    "    '''\n",
    "    count = int(get_id_count(term, db=db))\n",
    "    if count > int(retmax):\n",
    "        id_list = []\n",
    "        for ii in range(math.ceil(count / retmax)):\n",
    "            try:\n",
    "                ids = get_id(term, ii * retmax, retmax, db=db)\n",
    "                print('/'.join([str(ii), str(math.ceil(count / retmax))]) )\n",
    "                for id in ids:\n",
    "                    cu_mysql.execute('insert into pubmed_id_all values(%s)' , id)\n",
    "                con_mysql.commit()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                cu_mysql.execute('insert into error_pubmed_id_all values(%s)', (ii) )\n",
    "                con_mysql.commit()\n",
    "            # id_list += ids\n",
    "        # return id_list\n",
    "    else:\n",
    "        id_list = get_id(term, 0, count, db=db)\n",
    "        for id in id_list:\n",
    "            cu_mysql.execute('insert into pubmed_id_all values(%s)', id)\n",
    "            con_mysql.commit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def efetch(ids, db='pubmed'):\n",
    "    '''\n",
    "    根据id列表获取摘要信息\n",
    "    :param ids:\n",
    "    :param db:\n",
    "    :return:\n",
    "    '''\n",
    "    str_url = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=%s&id=%s' % (db, ids)\n",
    "    if db=='pubmed':\n",
    "        str_url = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=%s&id=%s&retmode=text&rettype=xml' % (db, ids)\n",
    "\n",
    "    request = urllib.request.Request(str_url)\n",
    "    xml = urllib.request.urlopen(request).read()\n",
    "    root = lxml.etree.XML(xml)\n",
    "    return root\n",
    "\n",
    "\n",
    "def  get_xpath_0(obj, xpath):\n",
    "    tmp = obj.xpath(xpath)\n",
    "    if tmp:\n",
    "        return tmp[0].text\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "# bug 太多弃用\n",
    "def process_pmc(term):\n",
    "    '''\n",
    "    处理pmc数据库文章\n",
    "    :param term:\n",
    "    :return:\n",
    "    '''\n",
    "    try:\n",
    "        root = efetch(term, db='pmc')\n",
    "        articles = root.xpath('//article')\n",
    "        # 对每一篇文章进行处理\n",
    "        for article in articles:\n",
    "            journal = article.xpath('.//journal-title')[0].text\n",
    "    #         journal-id journal-id-type=\"nlm-journal-id\"\n",
    "            if article.xpath('.//journal-id[@journal-id-type=\"nlm-journal-id\"]'):\n",
    "                journal_nlm_id = article.xpath('.//journal-id[@journal-id-type=\"nlm-journal-id\"]')[0].text\n",
    "            else:\n",
    "                journal_nlm_id = '0'\n",
    "            issn = article.xpath('.//issn')[0].text\n",
    "    #         print(issn)\n",
    "            title = article.xpath('.//article-title')[0].text\n",
    "            subject = article.xpath('.//subject')[0].text\n",
    "            pmid_tmp = article.xpath('.//article-id[@pub-id-type=\"pmid\"]')\n",
    "            if pmid_tmp:\n",
    "                pmid = pmid_tmp[0].text\n",
    "#                 pmid_tmp = get_xpath_0(article, './/article-id[@pub-id-type=\"pmid\"]')\n",
    "            else:\n",
    "                pmid = '0'\n",
    "            pmc_id = article.xpath('.//article-id[@pub-id-type=\"pmc\"]')[0].text\n",
    "            doi = article.xpath('.//article-id[@pub-id-type=\"doi\"]')[0].text\n",
    "            authors = article.xpath('.//contrib[@contrib-type=\"author\"]')\n",
    "            year = article.xpath('.//pub-date//year')[0].text\n",
    "            # 文章信息\n",
    "\n",
    "            keywords = article.xpath('.//kwd-group//kwd')\n",
    "            keyword_list = [kw.text for kw in keywords if kw.text]\n",
    "            keyword_join = ','.join(keyword_list)\n",
    "    #         ariticl_info = [pmc_id, pmid, doi, journal,journal_nlm_id, issn, title, subject, year, keyword_join]\n",
    "    #         print(ariticl_info)\n",
    "            cu_mysql.execute('insert into pmc_article(pmc_id, pmid, doi, journal,journal_nlm_id, issn, title, subject, year, keyword_join) \\\n",
    "            values(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)',\n",
    "                     (pmc_id, pmid, doi, journal,journal_nlm_id, issn, title, subject, year, keyword_join))\n",
    "            aff_list = article.xpath('.//aff[@id]')\n",
    "            aff_dict = {}\n",
    "            # 获取作者单位列表\n",
    "            for aff in aff_list:\n",
    "                aff_str = tostring(aff)\n",
    "                # 此处正则表达式， 因为pmc有</label> 和 <label/>两种，为兼顾两者，暂时采用 > 代替\n",
    "                aff_str_tmp = re.compile(r'(?<=>)[\\s\\S]*(?=</aff>)').findall(aff_str.decode('utf-8'))\n",
    "                if aff_str_tmp:\n",
    "                    aff_str = aff_str_tmp[0]\n",
    "                aff_id = aff.get('id')\n",
    "                aff_dict[aff_id] = aff_str\n",
    "\n",
    "                    # 通讯作者， 邮箱， PMC有两类，一类 是跟其他作者一起， 但用<xref ref-type=\"corresp\" rid=\"CR1\">*</xref> 区别\n",
    "            #<contrib contrib-type=\"author\">\n",
    "    #         <name>\n",
    "    #         <surname>Jiang</surname>\n",
    "    #         <given-names>Liwen</given-names>\n",
    "    #         </name>\n",
    "    #         <xref ref-type=\"aff\" rid=\"A1\">a</xref>\n",
    "    #         <xref ref-type=\"aff\" rid=\"A3\">c</xref>\n",
    "    #         <xref ref-type=\"corresp\" rid=\"CR1\">*</xref>\n",
    "    #         </contrib>\n",
    "    # 另一类\n",
    "    #     <contrib id=\"A3\" corresp=\"yes\" contrib-type=\"author\">\n",
    "\n",
    "    # 第一类\n",
    "    # 获取通讯作者邮箱\n",
    "            corresp_list = article.xpath('.//corresp[@id]')\n",
    "            corresp_dict = {}\n",
    "            for corresp_info in corresp_list:\n",
    "                corresp_id = corresp_info.get('id')\n",
    "                corresp_dict[corresp_id] = corresp_info.xpath('.//email')[0].text\n",
    "\n",
    "\n",
    "            author_index = 0\n",
    "            for author in authors:\n",
    "                author_index += 1\n",
    "                surname = author.xpath('.//name//surname')[0].text\n",
    "                given_names = author.xpath('.//name//given-names')[0].text\n",
    "    #             full_name = surname + given_names\n",
    "                email_tmp = author.xpath('.//email')\n",
    "                if email_tmp:\n",
    "                    email = email_tmp[0].text\n",
    "                else:\n",
    "                    email='NA'\n",
    "                # 是否通讯作者\n",
    "                # <xref ref-type=\"corresp\" rid=\"CR1\">*</xref>\n",
    "    #             corres = author.xpath('.//x')\n",
    "                corresp = 0\n",
    "                xref_corresp = author.xpath(\".//xref[@ref-type='corresp']\") # [@lang='eng']\n",
    "                if  xref_corresp:            \n",
    "                    corresp = 1\n",
    "                    corresp_id = xref_corresp[0].get('rid')\n",
    "                    email = corresp_dict[corresp_id]\n",
    "                # 通讯作者邮箱\n",
    "                # 获取单位\n",
    "                xref = author.xpath(\".//xref[@ref-type='aff']\")\n",
    "                for ii in range(len(xref)):\n",
    "                    if(xref[ii].get('ref-type') == 'aff' ):\n",
    "                        aff_name = aff_dict[xref[ii].get('rid')]\n",
    "    #                     print(aff_name)\n",
    "                    cu_mysql.execute('insert into pmc_authors(pmc_id, author_index, surname, given_names, email, corresp, aff_name) \\\n",
    "                                     values(%s, %s, %s, %s, %s, %s, %s)',\n",
    "                                     (pmc_id, author_index, surname, given_names, email, corresp, aff_name))\n",
    "\n",
    "    #       print(pmc_id, author_index, surname, given_names, email, corresp, aff_name)\n",
    "\n",
    "\n",
    "    #      以下为第二类\n",
    "            corresp_authors = article.xpath('.//contrib[@corresp=\"yes\"]')\n",
    "            for corresp_author in corresp_authors:\n",
    "                surname = corresp_author.xpath('.//surname')[0].text\n",
    "                given_names = corresp_author.xpath('.//given-names')[0].text\n",
    "    #             corresp_name = surname + given_names\n",
    "                email_tmp = corresp_author.xpath('.//email')\n",
    "                if email_tmp:\n",
    "                    email = email_tmp[0].text\n",
    "                else:\n",
    "                    email='NA'\n",
    "                # pmc_id, surname, given_names, email\n",
    "                cu_mysql.execute('insert into pmc_corresp_author(pmc_id, surname, given_names, email) \\\n",
    "                     values(%s, %s, %s, %s)',\n",
    "                     (pmc_id, surname, given_names, email))\n",
    "        con_mysql.commit()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        con_mysql.rollback()\n",
    "        cu_mysql.execute('insert into error_pmc values(%s, %s)', (term, str(e)))\n",
    "        con_mysql.commit()\n",
    "\n",
    "\n",
    "def process_pmc2(term):\n",
    "    '''\n",
    "    处理pmc数据库文章\n",
    "    :param term:\n",
    "    :return:\n",
    "    '''\n",
    "    try:\n",
    "        root = efetch(term, db='pmc')\n",
    "        articles = root.xpath('//article')\n",
    "        # 对每一篇文章进行处理\n",
    "        for article in articles:\n",
    "            journal = get_xpath_0(article, './/journal-title')\n",
    "    #         journal-id journal-id-type=\"nlm-journal-id\"\n",
    "            if article.xpath('.//journal-id[@journal-id-type=\"nlm-journal-id\"]'):\n",
    "                journal_nlm_id = article.xpath('.//journal-id[@journal-id-type=\"nlm-journal-id\"]')[0].text\n",
    "            else:\n",
    "                journal_nlm_id = '0'\n",
    "            issn = get_xpath_0(article, './/issn')\n",
    "    #         print(issn)\n",
    "            title = tostring(article.xpath('.//article-title')[0])\n",
    "            strinfo = re.compile('<[^>]*>')\n",
    "            title = strinfo.sub('',title.decode('utf-8'))\n",
    "        #get_xpath_0(article, './/article-title')\n",
    "            subject = get_xpath_0(article, './/subject')\n",
    "            pmid = get_xpath_0(article, './/article-id[@pub-id-type=\"pmid\"]')\n",
    "\n",
    "            pmc_id = get_xpath_0(article, './/article-id[@pub-id-type=\"pmc\"]')\n",
    "            doi = get_xpath_0(article, './/article-id[@pub-id-type=\"doi\"]')\n",
    "            authors = article.xpath('.//contrib[@contrib-type=\"author\"]')\n",
    "            year = get_xpath_0(article,'.//pub-date//year')\n",
    "            # 文章信息\n",
    "\n",
    "            keywords = article.xpath('.//kwd-group//kwd')\n",
    "            keyword_list = [kw.text for kw in keywords if kw.text]\n",
    "            keyword_join= '|'.join(keyword_list)\n",
    "    #         ariticl_info = [pmc_id, pmid, doi, journal,journal_nlm_id, issn, title, subject, year, keyword_join]\n",
    "    #         print(ariticl_info)\n",
    "\n",
    "    #             print(pmc_id, pmid, doi, journal,journal_nlm_id, issn, title, subject, year, keyword_join)\n",
    "            aff_list = article.xpath('.//aff[@id]')\n",
    "            aff_dict = {}\n",
    "            # 获取作者单位列表\n",
    "            first_aff = '0'\n",
    "            first_aff_flag = True\n",
    "            for aff in aff_list:\n",
    "                aff_str = tostring(aff)\n",
    "                # 此处正则表达式， 因为pmc有</label> 和 <label/>两种，为兼顾两者，暂时采用 > 代替\n",
    "                aff_str_tmp = re.compile(r'(?<=>)[\\s\\S]*(?=</aff>)').findall(aff_str.decode('utf-8'))\n",
    "\n",
    "                if aff_str_tmp:\n",
    "                    aff_str = aff_str_tmp[0]\n",
    "    #                     strinfo = re.compile('<[^>]*>')\n",
    "    #                     aff_str = strinfo.sub('',aff_str)\n",
    "                else:\n",
    "                    aff_str = '0'\n",
    "                aff_id = aff.get('id')\n",
    "                aff_dict[aff_id] = aff_str\n",
    "                if(first_aff_flag):\n",
    "                    first_aff = aff_str\n",
    "                    first_aff_flag = False\n",
    "            cu_mysql.execute('insert into pmc_article2(pmc_id, pmid, doi, journal,first_aff, issn, title, subject, year, keyword_join) \\\n",
    "                values(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)',\n",
    "                     (pmc_id, pmid, doi, journal,first_aff, issn, title, subject, year, keyword_join))\n",
    "                    # 通讯作者， 邮箱， PMC有两类，一类 是跟其他作者一起， 但用<xref ref-type=\"corresp\" rid=\"CR1\">*</xref> 区别\n",
    "            #<contrib contrib-type=\"author\">\n",
    "    #         <name>\n",
    "    #         <surname>Jiang</surname>\n",
    "    #         <given-names>Liwen</given-names>\n",
    "    #         </name>\n",
    "    #         <xref ref-type=\"aff\" rid=\"A1\">a</xref>\n",
    "    #         <xref ref-type=\"aff\" rid=\"A3\">c</xref>\n",
    "    #         <xref ref-type=\"corresp\" rid=\"CR1\">*</xref>\n",
    "    #         </contrib>\n",
    "    # 另一类\n",
    "    #     <contrib id=\"A3\" corresp=\"yes\" contrib-type=\"author\">\n",
    "\n",
    "    # 第一类\n",
    "    # 获取通讯作者邮箱\n",
    "\n",
    "            corresp_dict = {}\n",
    "            if article.xpath('.//author-notes'):\n",
    "                corresp_list = article.xpath('.//author-notes')[0]\n",
    "                for corresp_info in list(corresp_list):\n",
    "                    corresp_id = corresp_info.get('id')\n",
    "                    corresp_dict[corresp_id] =get_xpath_0(corresp_info, './/email')\n",
    "\n",
    "\n",
    "            author_index = 0\n",
    "            for author in authors:\n",
    "                author_index += 1\n",
    "                surname = get_xpath_0(author, './/name//surname')\n",
    "                given_names = get_xpath_0(author,'.//name//given-names')\n",
    "    #             full_name = surname + given_names\n",
    "                email_tmp = author.xpath('.//email')\n",
    "                if email_tmp:\n",
    "                    email = email_tmp[0].text\n",
    "                else:\n",
    "                    email='NA'\n",
    "                # 是否通讯作者\n",
    "                # <xref ref-type=\"corresp\" rid=\"CR1\">*</xref>\n",
    "    #             corres = author.xpath('.//x')\n",
    "                corresp = 0\n",
    "                xref_corresp = author.xpath(\".//xref[@ref-type='corresp']\") # [@lang='eng']\n",
    "                if  xref_corresp:            \n",
    "                    corresp = 1\n",
    "                    corresp_id = xref_corresp[0].get('rid')\n",
    "                    email = corresp_dict[corresp_id]\n",
    "                # 通讯作者邮箱\n",
    "                # 获取单位\n",
    "                xref = author.xpath(\".//xref[@ref-type='aff']\")\n",
    "                for ii in range(len(xref)):\n",
    "                    if(xref[ii].get('ref-type') == 'aff' ):\n",
    "                        aff_flag_list = xref[ii].get('rid').split(' ') # 存在 'a1 a2' 这种情况,所以需要分割后处理\n",
    "                        for aff_flag in aff_flag_list:\n",
    "                            aff_name = aff_dict[aff_flag]\n",
    "                            cu_mysql.execute('insert into pmc_authors2(pmc_id, author_index, surname, given_names, email, corresp, aff_name) \\\n",
    "                                             values(%s, %s, %s, %s, %s, %s, %s)',\n",
    "                                             (pmc_id, author_index, surname, given_names, email, corresp, aff_name))\n",
    "\n",
    "\n",
    "\n",
    "    #      以下为第二类\n",
    "            corresp_authors = article.xpath('.//contrib[@corresp=\"yes\"]')\n",
    "            for corresp_author in corresp_authors:\n",
    "                surname = get_xpath_0(corresp_author, './/surname')\n",
    "                given_names = get_xpath_0(corresp_author, './/given-names')\n",
    "    #             corresp_name = surname + given_names\n",
    "                email = get_xpath_0(corresp_author,'.//email')\n",
    "\n",
    "                # pmc_id, surname, given_names, email\n",
    "                cu_mysql.execute('insert into pmc_corresp_author2(pmc_id, surname, given_names, email) \\\n",
    "                     values(%s, %s, %s, %s)',\n",
    "                     (pmc_id, surname, given_names, email))\n",
    "        con_mysql.commit()\n",
    "    except Exception as e:\n",
    "        con_mysql.rollback()\n",
    "        cu_mysql.execute('insert into error_pmc2 values(%s, %s)', (term, str(e)))\n",
    "        con_mysql.commit()\n",
    "\n",
    "\n",
    "# 多进程处理 pmc数据\n",
    "\n",
    "import multiprocessing\n",
    "def multi_process_pmc():\n",
    "    con_mysql = pymysql.connect(host='localhost', user='root', passwd='', db='xiaobaifinder', charset='utf8')\n",
    "    cu_mysql = con_mysql.cursor()\n",
    "    cu_pmc_id = con_mysql.cursor()\n",
    "    cu_pmc_id.execute('select distinct * from pmc_id where pmc_id not in (select distinct pmc_id from pmc_article2)')\n",
    "    pmc_list = cu_pmc_id.fetchall()    \n",
    "    pool = multiprocessing.Pool(processes= 10) # 设置进程数\n",
    "    proc_index = 0\n",
    "    for pmc_id in pmc_list:\n",
    "        proc_index += 1\n",
    "    #     print('complete percent:%2.2f%s'%(proc_index/len(pmc_list)*100,'%'),end='\\r') \n",
    "        pool.apply_async(process_pmc2, (pmc_id[0], ))\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "# pmc term\n",
    "def get_pmc_id():\n",
    "    con_mysql = pymysql.connect(host='localhost', user='root', passwd='', db='xiaobaifinder', charset='utf8')\n",
    "    cu_mysql = con_mysql.cursor()\n",
    "    cu_mysql.execute('create table if not exists pmc_id(pmc_id varchar(12))')\n",
    "    cu_mysql.execute('create table if not exists error_pmc_id(page int)')\n",
    "    con_mysql.commit()\n",
    "    # con = sqlite3.connect('pubmed.db')\n",
    "    # cu = con.cursor()\n",
    "    # # cu.execute('DROP TABLE IF EXISTS dxy')\n",
    "    # cu.execute('CREATE TABLE IF NOT EXISTS pmid (pmid varchar(12))')\n",
    "    # cu.execute('CREATE TABLE IF NOT EXISTS error_pmid(page int)')\n",
    "    # con.commit()\n",
    "\n",
    "    # 获取pmc id\n",
    "    term = '(PRC[Affiliation] OR China[Affiliation]) AND (\"2015/10/1\"[PDat] : \"2015/12/31\"[PDat]) '\n",
    "    query_id(term,con_mysql, cu_mysql, db = 'pmc')\n",
    "\n",
    "    # 获取 pmc 信息\n",
    "\n",
    "    cu_mysql.close()\n",
    "    con_mysql.close()\n",
    "\n",
    "def get_pubmed_id():\n",
    "    con_mysql = pymysql.connect(host='localhost', user='root', passwd='', db='xiaobaifinder', charset='utf8')\n",
    "    cu_mysql = con_mysql.cursor()\n",
    "    cu_mysql.execute('create table if not exists pubmed_id(pmc_id varchar(12))')\n",
    "    cu_mysql.execute('create table if not exists error_pubmed_id(page int)')\n",
    "    con_mysql.commit()\n",
    "    # con = sqlite3.connect('pubmed.db')\n",
    "    # cu = con.cursor()\n",
    "    # # cu.execute('DROP TABLE IF EXISTS dxy')\n",
    "    # cu.execute('CREATE TABLE IF NOT EXISTS pmid (pmid varchar(12))')\n",
    "    # cu.execute('CREATE TABLE IF NOT EXISTS error_pmid(page int)')\n",
    "    # con.commit()\n",
    "\n",
    "    # 获取pmc id\n",
    "    term = '(PRC[Affiliation] OR China[Affiliation]) AND (\"2015/10/1\"[PDat] : \"2015/12/31\"[PDat]) '\n",
    "    query_id(term)\n",
    "    cu_mysql.close()\n",
    "    con_mysql.close()\n",
    "\n",
    "def process_pubmed(term):\n",
    "    '''\n",
    "    处理pubmed数据库文章\n",
    "    :param term:\n",
    "    :return:\n",
    "    '''\n",
    "    try:\n",
    "        root = efetch(term, db='pubmed')\n",
    "        articles = root.xpath('//PubmedArticle')\n",
    "        # 对每一篇文章进行处理\n",
    "        for article in articles:\n",
    "            journal = get_xpath_0(article, './/Journal//Title')\n",
    "    #         journal-id journal-id-type=\"nlm-journal-id\"\n",
    "            issn = get_xpath_0(article, './/ISSN')\n",
    "    #         print(issn)\n",
    "            title = get_xpath_0(article, './/ArticleTitle')\n",
    "            # subject = article.xpath('.//subject')[0].text\n",
    "            pmid = get_xpath_0(article, './/PMID')\n",
    "            doi = get_xpath_0(article, './/ELocationID[@EIdType=\"doi\"]')\n",
    "            if doi == '0':\n",
    "                doi = get_xpath_0(article, './/ArticleId[@IdType=\"doi\"]')\n",
    "            year = get_xpath_0(article, './/PubMedPubDate[@PubStatus=\"pubmed\"]//Year')\n",
    "            # 文章信息pub-datePubMedPubDate\n",
    "            # mesh\n",
    "            if article.xpath('.//MeshHeading//DescriptorName[@MajorTopicYN=\"N\"]'):\n",
    "                mesh = article.xpath('.//MeshHeading//DescriptorName[@MajorTopicYN=\"N\"]')\n",
    "                mesh_list = [kw.text for kw in mesh]\n",
    "                mesh_join = '|'.join(mesh_list)\n",
    "            else:\n",
    "                mesh_join='0'\n",
    "    # keywords\n",
    "            if article.xpath('.//Keyword[@MajorTopicYN=\"N\"]'):\n",
    "                keyword = article.xpath('.//Keyword[@MajorTopicYN=\"N\"]')\n",
    "                keyword_list = [kw.text for kw in keyword]\n",
    "                keyword_join = '|'.join(keyword_list)\n",
    "            else:\n",
    "                keyword_join = '0'\n",
    "            cu_mysql.execute('insert into  pubmed_articles(pmid, journal, issn, title, doi, year, mesh_join, keyword_join) \\\n",
    "    values(%s, %s, %s, %s,%s, %s, %s, %s)', (pmid, journal, issn, title, doi, year, mesh_join, keyword_join))\n",
    "            # print(pmid, issn, title, doi, year, mesh_join, keyword_join)\n",
    "            authors = article.xpath('.//Author[@ValidYN=\"Y\"]')\n",
    "            author_index = 0\n",
    "            for author in authors:\n",
    "                author_index += 1\n",
    "                surname = get_xpath_0(author, './/LastName')\n",
    "                given_names = get_xpath_0(author, './/ForeName')\n",
    "                aff = get_xpath_0(author, './/Affiliation')\n",
    "                cu_mysql.execute('insert into  pubmed_author(pmid, author_index, surname, given_names, aff) \\\n",
    "    values(%s, %s, %s, %s, %s)',              (pmid, author_index, surname, given_names, aff))\n",
    "                # print(pmid, author_index, surname, given_names, aff)\n",
    "\n",
    "\n",
    "    #      以下为第二类\n",
    "\n",
    "        con_mysql.commit()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        con_mysql.rollback()\n",
    "        cu_mysql.execute('insert into error_pubmed values(%s, %s)', (term, str(e)))\n",
    "        con_mysql.commit()\n",
    "\n",
    "def multi_process_pubmed():\n",
    "    con_mysql = pymysql.connect(host='localhost', user='root', passwd='', db='xiaobaifinder', charset='utf8')\n",
    "    cu_mysql = con_mysql.cursor()\n",
    "    # 差集\n",
    "    cu_mysql.execute('select pmid from pubmed_id where pmid not in (select pmid from pmc_article2) and pmid not in  (select pmid from pubmed_articles);')\n",
    "    pmid_list = cu_mysql.fetchall()\n",
    "    pool = multiprocessing.Pool(processes= 10) # 设置进程数\n",
    "    for pmid in pmid_list:\n",
    "        pool.apply_async(process_pubmed, (pmid[0], ))\n",
    "    # process_pubmed('24735618')\n",
    "    # efetch('24735618')\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    cu_mysql.close()\n",
    "    con_mysql.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50595\n",
      "1/50595\n",
      "2/50595\n",
      "3/50595\n",
      "4/50595\n",
      "5/50595\n",
      "6/50595\n",
      "7/50595\n",
      "8/50595\n",
      "9/50595\n",
      "10/50595\n",
      "11/50595\n",
      "12/50595\n",
      "13/50595\n",
      "14/50595\n",
      "15/50595"
     ]
    }
   ],
   "source": [
    "con_mysql = pymysql.connect(host='localhost', user='root', passwd='', db='xiaobaifinder', charset='utf8')\n",
    "cu_mysql = con_mysql.cursor()\n",
    "cu_mysql.execute('create table if not exists pubmed_id_all(pmc_id varchar(12))')\n",
    "cu_mysql.execute('create table if not exists error_pubmed_id_all(page int)')\n",
    "con_mysql.commit()\n",
    "# con = sqlite3.connect('pubmed.db')\n",
    "# cu = con.cursor()\n",
    "# # cu.execute('DROP TABLE IF EXISTS dxy')\n",
    "# cu.execute('CREATE TABLE IF NOT EXISTS pmid (pmid varchar(12))')\n",
    "# cu.execute('CREATE TABLE IF NOT EXISTS error_pmid(page int)')\n",
    "# con.commit()\n",
    "\n",
    "# 获取pmc id\n",
    "term = '\"2011/1/1\"[PDat] : \"2015/12/31\"[PDat] '\n",
    "query_id(term)\n",
    "cu_mysql.close()\n",
    "con_mysql.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
