{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import pycurl\n",
    "import pymysql\n",
    "import urllib.parse\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from lxml.html import fromstring, tostring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeout=60\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_catch(func):\n",
    "    def wrapper(*args, **kw):\n",
    "        try:\n",
    "            func(*args, **kw)\n",
    "        except Exception as e:\n",
    "            pmid = args[0]\n",
    "            with open('./errors/'+ str(pmid) + '.html', 'w') as f:\n",
    "                f.write(text)\n",
    "            cu.execute('insert into journal_error values(%s, %s)', (pmid, str(e)))\n",
    "            con.commit()\n",
    "#         return func(*args, **kw)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/bth468\n",
      "http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/bth486\n",
      "http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/bti090\n",
      "http://jxb.oxfordjournals.org/lookup/doi/10.1093/jxb/eri013\n",
      "http://ndt.oxfordjournals.org/cgi/doi/10.1093/ndt/gfh574\n",
      "http://humrep.oxfordjournals.org/lookup/doi/10.1093/humrep/deh583\n",
      "http://humrep.oxfordjournals.org/lookup/doi/10.1093/humrep/deh594\n",
      "http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/bti197\n",
      "http://bioinformatics.oxfordjournals.org/cgi/doi/10.1093/bioinformatics/bti211\n",
      "http://humrep.oxfordjournals.org/lookup/doi/10.1093/humrep/deh676\n",
      "http://humrep.oxfordjournals.org/lookup/doi/10.1093/humrep/deh668\n",
      "http://cardiovascres.oxfordjournals.org/cgi/doi/10.1016/j.cardiores.2004.09.027\n",
      "http://cardiovascres.oxfordjournals.org/cgi/doi/10.1016/j.cardiores.2004.09.020\n",
      "http://femsle.oxfordjournals.org/cgi/doi/10.1016/j.femsle.2004.10.046\n",
      "http://femsle.oxfordjournals.org/cgi/doi/10.1016/j.femsle.2004.11.021\n",
      "http://www.mutage.oxfordjournals.org/cgi/doi/10.1093/mutage/gei067\n",
      "http://www.ije.oxfordjournals.org/cgi/doi/10.1093/ije/dyi296\n",
      "http://femsec.oxfordjournals.org/cgi/doi/10.1111/j.1574-6941.2005.00015.x\n",
      "http://femsec.oxfordjournals.org/cgi/doi/10.1111/j.1574-6941.2005.00033.x\n",
      "http://ndt.oxfordjournals.org/cgi/doi/10.1093/ndt/gfk036\n"
     ]
    }
   ],
   "source": [
    "con = pymysql.connect(host='localhost', user='root', passwd='', db='xiaobaifinder', charset='utf8')\n",
    "cu_r = con.cursor()\n",
    "cu = con.cursor()\n",
    "cu_r.execute('select link from doi_link where link like \"%oxfordjournals%\" limit 20')\n",
    "link_list = cu_r.fetchall()\n",
    "for link in link_list:\n",
    "    print(link[0])\n",
    "cu_r.close()\n",
    "cu.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = link_list[0]\n",
    "print(url)\n",
    "text = requests.get(url, headers = headers,timeout=timeout).content.decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tandfonline(pmid,url):\n",
    "    text = requests.get(url, headers = headers,timeout=timeout).content.decode('utf-8')\n",
    "    try:\n",
    "        root = fromstring(text)\n",
    "        author_index = 0            \n",
    "        for author_li in root.cssselect('span.hlFld-ContribAuthor'):\n",
    "    #         print(tostring(author_li))\n",
    "            if 'NLM_degrees' in author_li.get('class'):\n",
    "                continue;\n",
    "            corresp=0\n",
    "            author=None\n",
    "            author_index +=1\n",
    "            author_aff_list=[]\n",
    "            author_aff_name=None\n",
    "            email=None\n",
    "            author = author_li.find('a').text_content().strip()\n",
    "    #             print(author)\n",
    "    #         author = re.compile('[0-9]').sub('', author)\n",
    "            sup = author_li\n",
    "            for ii in range(5):\n",
    "                if sup  and '*' in sup.text_content():\n",
    "                    corresp = 1\n",
    "                elif sup:\n",
    "                    sup = sup.getnext()\n",
    "                else:\n",
    "                    break\n",
    "                if sup and sup.tag and sup.tag == 'span':\n",
    "                    break        \n",
    "    #         print(pmid, author_index, author, author_aff_name, email, corresp)\n",
    "    #         cu.execute('insert into journal_author values(%s, %s, %s, %s, %s, %s)',\n",
    "    #            (pmid, author_index, author, author_aff_name, email, corresp,))\n",
    "    #         con.commit() \n",
    "        # keywords\n",
    "        keywords = [kw.find('a').text for kw in  root.cssselect('ul.keywords li')]\n",
    "        for kw in keywords:\n",
    "            if kw:\n",
    "                cu.execute('insert into journal_keyword values(%s, %s)', (pmid, kw.replace(';', '').strip(),))\n",
    "                con.commit()\n",
    "    except Exception as e:\n",
    "        with open('./errors/'+ str(pmid) + '.html', 'w') as f:\n",
    "            f.write(text)\n",
    "        cu.execute('insert into journal_error values(%s, %s)', (pmid, str(e)))\n",
    "        con.commit()    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rsc(pmid, url):\n",
    "    text = requests.get(url, headers = headers,timeout=timeout).content.decode('utf-8')\n",
    "    try:\n",
    "        root = fromstring(text)\n",
    "        # aff\n",
    "        aff_dict={}\n",
    "        aff_index = 0\n",
    "        aff_list = root.cssselect('div.show_aff_content')\n",
    "        corresp_email=[]\n",
    "        for aff in aff_list:\n",
    "            aff_index +=1\n",
    "            if aff.find('div').text.strip() == '*':\n",
    "                aff_index -=1\n",
    "                continue\n",
    "            email = ''\n",
    "            email_div = aff.findall('div')[1].find('a')\n",
    "            if email_div is not None and email_div.get('title'):\n",
    "                email =  email_div.get('title')\n",
    "                corresp_email.append(email)\n",
    "\n",
    "            sup = aff.cssselect('sup.affiliation_sup')[0].text_content().strip()\n",
    "    #             print(sup)\n",
    "            aff_name = aff.findall('div')[1].text.replace('E-mail:', '').replace(email, '').strip()\n",
    "\n",
    "            # 查找email\n",
    "            aff_dict[sup] = aff_name        \n",
    "            cu.execute('insert into journal_aff (pmid, aff_index, aff_name) values(%s, %s, %s)', (pmid, aff_index, aff_name,))\n",
    "            con.commit()\n",
    "    ## author\n",
    "        author_index = 0\n",
    "        for author_li in root.cssselect('span.author_link'):\n",
    "    #         print(tostring(author_li))\n",
    "            corresp=0\n",
    "            author=None\n",
    "            email = None\n",
    "            author_aff_name = None\n",
    "            author_index +=1\n",
    "            author_aff_list=[]\n",
    "            author = author_li.find('a').text_content().strip()\n",
    "    #         author = re.compile('[0-9]').sub('', author)\n",
    "\n",
    "            sups = author_li.findall('sup')\n",
    "            for sup in sups:\n",
    "                aff_name = aff_dict[sup.text]\n",
    "                author_aff_list.append(aff_name)\n",
    "\n",
    "            authro_corresp = author_li.find('span')\n",
    "    #         print(tostring(authro_corresp[0]).text_content)\n",
    "            if authro_corresp is not None and '*' in authro_corresp.text_content():\n",
    "\n",
    "                corresp=1\n",
    "                email = corresp_email.pop(0)\n",
    "            for author_aff_name in author_aff_list:\n",
    "    #             print(pmid, author_index, author, author_aff_name, email, corresp)\n",
    "                cu.execute('insert into journal_author values(%s, %s, %s, %s, %s, %s)',\n",
    "                   (pmid, author_index, author, author_aff_name, email, corresp,))\n",
    "                con.commit() \n",
    "    # keywords\n",
    "    except Exception as e:\n",
    "        with open('./errors/'+ str(pmid) + '.html', 'w') as f:\n",
    "            f.write(text)\n",
    "        cu.execute('insert into journal_error values(%s, %s)', (pmid, str(e)))\n",
    "        con.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "def acs(pmid, url):\n",
    "    text = requests.get(url, headers = headers,timeout=timeout).content.decode('utf-8')\n",
    "\n",
    "    try:\n",
    "        root = fromstring(text)\n",
    "        # aff\n",
    "        aff_dict={}\n",
    "        aff_index = 0\n",
    "        aff_list = root.cssselect('div.affiliations div')\n",
    "        first = None\n",
    "        if len(aff_list)==1:\n",
    "            first=1\n",
    "        for aff in aff_list:\n",
    "            aff_index +=1\n",
    "\n",
    "            if not first and aff.find('sup'):\n",
    "                sup = aff.find('sup').text_content()\n",
    "#                 print(sup)\n",
    "                aff_name = aff.text_content().replace(sup, '').replace('\\r\\n', '').strip()\n",
    "                aff_dict[sup] = aff_name\n",
    "#                 print(aff_name)\n",
    "            else:\n",
    "                aff_name = aff.text_content().replace('\\r\\n', '').strip()\n",
    "                aff_dict['first']=aff_name\n",
    "                cu.execute('insert into journal_aff (pmid, aff_index, aff_name) values(%s, %s, %s)', (pmid, aff_index, aff_name,))\n",
    "                con.commit()\n",
    "        corresp_email = [email.text for email in root.cssselect('div#correspondence a')]\n",
    "        # author\n",
    "        author_index=0\n",
    "\n",
    "        equal = re.compile('Authors with equal contribution').findall(text)\n",
    "\n",
    "        for author_li in root.cssselect('div#authors>span.hlFld-ContribAuthor'):\n",
    "    #         print(tostring(author_li))\n",
    "            corresp=0\n",
    "            author=None\n",
    "            email = None\n",
    "            author_aff_name = None\n",
    "            author_index +=1\n",
    "            author_aff_list=[]\n",
    "            author = author_li.text_content().replace(',', '').replace('and', '').replace('*', '').strip()\n",
    "            author = re.compile('[0-9]').sub('', author)\n",
    "            if not first:\n",
    "                sups = author_li.findall('a.NLM_xref-aff')\n",
    "                for sup in sups:\n",
    "                    aff_name = aff_dict[sup.text]\n",
    "                author_aff_list.append(aff_name)\n",
    "            else:\n",
    "                author_aff_list.append(aff_dict['first'])\n",
    "            authro_corresp = author_li.cssselect('a.ref')\n",
    "    #         print(tostring(authro_corresp[0]).text_content)\n",
    "            if authro_corresp and authro_corresp[0].text_content() == '*':\n",
    "\n",
    "                corresp=1\n",
    "                if corresp_email:\n",
    "                    email = corresp_email.pop(0)\n",
    "            for author_aff_name in author_aff_list:\n",
    "    #             pass\n",
    "#                     print(pmid, author_index, author, author_aff_name, email, corresp)\n",
    "                    cu.execute('insert into journal_author values(%s, %s, %s, %s, %s, %s)',\n",
    "                       (pmid, author_index, author, author_aff_name, email, corresp,))\n",
    "                    con.commit() \n",
    "        # keywords\n",
    "        keywords = [kw.text for kw in  root.cssselect('div.keywords a')]\n",
    "#         print(keywords)\n",
    "        for kw in keywords: \n",
    "            if kw:\n",
    "#                 print(kw.strip())\n",
    "                cu.execute('insert into journal_keyword values(%s, %s)', (pmid, kw.strip(),))\n",
    "                con.commit()\n",
    "    except Exception as e:\n",
    "        with open('./errors/'+ str(pmid) + '.html', 'w') as f:\n",
    "            f.write(text)\n",
    "        cu.execute('insert into journal_error values(%s, %s)', (pmid, str(e)))\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wiley(pmid, url):\n",
    "    # wiley 存在问题， 个别时候 * 即表示共同第一又表示通讯, 已解决\n",
    "    text = requests.get(url, headers = headers,timeout=timeout).content.decode('utf-8')\n",
    "    try:\n",
    "        root = fromstring(text)\n",
    "        new = root.cssselect('a#wol1backlink')\n",
    "        if new:\n",
    "#             print(new)\n",
    "            url= new[0].get('href')\n",
    "            text = requests.get(url, headers = headers,timeout=timeout).content.decode('utf-8')\n",
    "            root = fromstring(text)\n",
    "        # aff\n",
    "#authorsAffiliations---------\n",
    "#         if not isinstance(text, str):\n",
    "#             text = text.decode('utf-8')\n",
    "        aff_dict={}\n",
    "        aff_index = 0\n",
    "        aff_list = root.cssselect('ol#authorsAffiliations li')\n",
    "        first = None # 单位的数目\n",
    "        if len(aff_list)==1:\n",
    "            first=1\n",
    "        for aff in aff_list:\n",
    "            aff_index +=1\n",
    "            aff_name = aff.find('p').text_content()\n",
    "            if not first:\n",
    "                sup = aff.find('span').text_content()\n",
    "                aff_dict[sup] = aff_name\n",
    "            else:\n",
    "                aff_dict['first']=aff_name\n",
    "            cu.execute('insert into journal_aff (pmid, aff_index, aff_name) values(%s, %s, %s)', (pmid, aff_index, aff_name,))\n",
    "            con.commit()\n",
    "        corresp_email = [email.text for email in root.cssselect('p#correspondence a')]\n",
    "        # author\n",
    "        author_index=0\n",
    "\n",
    "        equal = re.compile('Authors with equal contribution').findall(text)\n",
    "\n",
    "        for author_li in root.cssselect('ol#authors li'):\n",
    "#             print(tostring(author_li))\n",
    "            corresp=0\n",
    "            author=None\n",
    "            email = None\n",
    "            author_aff_name = None\n",
    "            author_index +=1\n",
    "            author = author_li.text_content().replace(',', '').replace('and', '').replace('*', '').strip()\n",
    "            author = re.compile('[0-9]').sub('', author)\n",
    "            author_aff_list = []\n",
    "            author_sup = author_li.find('sup')\n",
    "            if author_sup is not None: \n",
    "                sups = author_sup.text_content().split(',')\n",
    "#                 print(sups)\n",
    "                for sup in sups:\n",
    "                    if sup in  aff_dict:# 标号是不是在sups里面\n",
    "                        author_aff_list.append(aff_dict[sup])\n",
    "    #                 elif first:\n",
    "    #                     author_aff_list.append(aff_dict['first'])\n",
    "                    if (sup=='*' and equal and (author_index>2)) or (not equal and sup=='*') : # 解决共同第一的问题\n",
    "                        corresp=1\n",
    "                        if corresp_email:\n",
    "                            email = corresp_email.pop(0)\n",
    "#                         print(email,equal)\n",
    "            if first:#没有 sup也就是只有一个单位\n",
    "                author_aff_list.append(aff_name)\n",
    "\n",
    "            for author_aff_name in author_aff_list:\n",
    "                cu.execute('insert into journal_author values(%s, %s, %s, %s, %s, %s)',\n",
    "                   (pmid, author_index, author, author_aff_name, email, corresp,))\n",
    "#                 print(pmid, author_index, author, author_aff_name, email, corresp,)\n",
    "                con.commit()\n",
    "\n",
    "        #keyword\n",
    "        for kw in root.cssselect('ul.keywordList li'):\n",
    "    #         print(kw.text_content().replace(';', '').strip())\n",
    "            cu.execute('insert into journal_keyword values(%s, %s)', (pmid, kw.text_content().replace(';', '').strip(),))\n",
    "            con.commit()\n",
    "    except Exception as e:\n",
    "        with open('./errors/'+ str(pmid) + '.html', 'w') as f:\n",
    "            f.write(text)\n",
    "        cu.execute('insert into journal_error values(%s, %s)', (pmid, str(e)))\n",
    "        con.commit()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# url = 'http://link.springer.com/article/10.1007%2Fs12149-015-1046-7'\n",
    "def springer(pmid, url):\n",
    "#     response = requests.get(url, headers=headers)\n",
    "    text = requests.get(url, headers = headers,timeout=timeout).content.decode('utf-8')\n",
    "    try:\n",
    "        root = fromstring(text)\n",
    "        # aff\n",
    "        aff_index = 0\n",
    "        for aff in root.cssselect('ul.author-affiliations li'):\n",
    "            aff_index +=1\n",
    "            for span in aff.findall('span'):\n",
    "                if 'affiliation' in span.get('class'):\n",
    "                    aff_name = span.text_content().strip()\n",
    "                    cu.execute('insert into journal_aff (pmid, aff_index, aff_name) values(%s, %s, %s)', (pmid, aff_index, aff_name,))\n",
    "                    con.commit()\n",
    "        # get email list from the page footer     \n",
    "        email_dict={}\n",
    "        email_index = 0\n",
    "        for author_li in root.cssselect('ul.authors li'):\n",
    "            email_index += 1\n",
    "            for a in author_li.findall('a'):\n",
    "                if 'envelope' in a.get('class'):\n",
    "#                     corresp = 1\n",
    "                    email_e = a.get('title')\n",
    "                    email_dict[str(email_index)] = email_e\n",
    "        \n",
    "        # get  author\n",
    "#         print(email_dict)\n",
    "        author_index=0\n",
    "        for li in root.cssselect('ul.AuthorNames li'):\n",
    "            if li.get('class') == 'AuthorNames_moreLink' or li.get('class') == 'AuthorNames_hideLink':\n",
    "                continue\n",
    "            corresp=0\n",
    "            author=None\n",
    "            email = None\n",
    "            author_aff_name = None\n",
    "            author_index +=1\n",
    "            if li.cssselect('span.AuthorName') is not None:\n",
    "#                 print(tostring(li))\n",
    "                author = li.cssselect('span.AuthorName')[0].text.replace('&nbsp', ' ')\n",
    "#                 print(author)\n",
    "                if str(author_index) in email_dict:\n",
    "                    email = email_dict[str(author_index)]\n",
    "#                     print(email)\n",
    "            li_a = li.find('a')\n",
    "            if li_a is not None and 'mailto' in li_a.get('href'):\n",
    "                corresp=1\n",
    "                email = li_a.get('href').replace('mailto:', '')\n",
    "            \n",
    "            author_aff_list = li.cssselect('span.AuthorsName_affiliation span')\n",
    "            for author_aff in author_aff_list:\n",
    "                author_aff_name = author_aff.text_content()\n",
    "                cu.execute('insert into journal_author values(%s, %s, %s, %s, %s, %s)',\n",
    "                               (pmid, author_index, author, author_aff_name, email, corresp,))\n",
    "                con.commit()\n",
    "            \n",
    "        # keywords\n",
    "    #     keywords = root.cssselect('span.Keyword')\n",
    "        for kw in root.cssselect('span.Keyword'):\n",
    "            cu.execute('insert into journal_keyword values(%s, %s)', (pmid, kw.text_content().strip(),))\n",
    "            con.commit()\n",
    "    except Exception as e:\n",
    "        with open('./errors/'+ str(pmid) + '.html', 'w') as f:\n",
    "            f.write(text)\n",
    "        cu.execute('insert into journal_error values(%s, %s)', (pmid, str(e),))\n",
    "        con.commit()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# con = pymysql.connect(host='localhost', user='root', passwd='', db='xiaobaifinder', charset='utf8')\n",
    "# cu = con.cursor()\n",
    "# # cu_r = con.cursor()\n",
    "# # cu_r.execute('select pmid,link from doi_link where link like \"%wiley%\" limit 100,10')\n",
    "# # link_list = cu_r.fetchall()\n",
    "# # for link in link_list:\n",
    "# #     wiley(link[0], link[1])\n",
    "# # print(link_list)\n",
    "# # url = 'http://link.springer.com/article/10.1007%2Fs40261-015-0366-7'\n",
    "# link = 'http://onlinelibrary.wiley.com/wol1/doi/10.1002/anie.201508505/abstract'\n",
    "# wiley(1111, link)\n",
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def elsevier(pmid, url):\n",
    "    response = requests.get(url,timeout=timeout)\n",
    "#     server = response.headers['Server']\n",
    "#     if 'sciencedirect' in  server:\n",
    "    get_sciencedirect(pmid, response.content)\n",
    "#     else:\n",
    "#         cu.execute('insert into journal_error values(%s, %s)', (pmid, str(server)))\n",
    "#         con.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sciencedirect(pmid, text):\n",
    "    try:\n",
    "        \n",
    "        root = fromstring(text)\n",
    "    #     ul = root.cssselect('ul.authorGroup')[0]\n",
    "        # aff\n",
    "        aff_dict = {}\n",
    "        aff_index = 0\n",
    "        for aff in root.cssselect('ul.affiliation li'):\n",
    "            aff_index +=1\n",
    "            aff_id = aff.get('id')\n",
    "            aff_name = aff.find('span').text_content()\n",
    "            aff_dict[aff_id] = str(aff_name)\n",
    "            cu.execute('insert into journal_aff (pmid, aff_index, aff_name) values(%s, %s, %s)', (pmid, aff_index, aff_name,))\n",
    "            con.commit()\n",
    "        # author\n",
    "        author_index = 0\n",
    "        for author_li in root.cssselect('ul.authorGroup li'):\n",
    "            a_list = author_li.findall('a')\n",
    "            corresp=0\n",
    "            author=None\n",
    "            email = None\n",
    "            author_aff_name = None\n",
    "            author_index +=1\n",
    "            author_aff_list = []\n",
    "            for a in a_list:\n",
    "                if 'authorName' in a.get('class'):\n",
    "                    author = a.text_content()\n",
    "                if a.get('title') and 'Corresponding author contact information' in a.get('title'):\n",
    "                    corresp = 1\n",
    "    #                 print(corresp)\n",
    "                if a.get('class') and a.get('href') and 'auth_mail' in a.get('class'):\n",
    "                    email = a.get('href').replace('mailto:', '')\n",
    "    #                 print(email)\n",
    "                if a.get('title') and 'Affiliation' in a.get('title') or len(aff_dict)==1:\n",
    "\n",
    "                    if len(aff_dict) == 1:\n",
    "    #                     author_aff_name=aff_dict[aff_id]\n",
    "                        author_aff_list.append(aff_dict[aff_id])\n",
    "                    else:\n",
    "                        aff = a.get('href').replace('#', '')\n",
    "    #                     author_aff_name = aff_dict[aff]\n",
    "                        author_aff_list.append(aff_dict[aff])\n",
    "            if author_aff_list:\n",
    "                for author_aff_name in author_aff_list:\n",
    "                    cu.execute('insert into journal_author values(%s, %s, %s, %s, %s, %s)',\n",
    "                               (pmid, author_index, author, author_aff_name, email, corresp,))\n",
    "                    con.commit()\n",
    "            else:\n",
    "                cu.execute('insert into journal_author values(%s, %s, %s, %s, %s, %s)',\n",
    "                               (pmid, author_index, author, author_aff_name, email, corresp,))\n",
    "                con.commit()\n",
    "\n",
    "        #keywords\n",
    "        keywords = root.cssselect('ul.keyword li')\n",
    "        for kw in keywords:\n",
    "            cu.execute('insert into journal_keyword values(%s, %s)', (pmid, kw.text_content().replace(';', '').strip(),))\n",
    "            con.commit()\n",
    "    except Exception as e:\n",
    "        with open('./errors/'+ str(pmid) + '.html', 'w') as f:\n",
    "            f.write(text)\n",
    "        cu.execute('insert into journal_error values(%s, %s)', (pmid, str(e)))\n",
    "        con.commit()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_website(url):\n",
    "    netloc = urllib.parse.urlsplit(url).netloc\n",
    "    out_split = netloc.split('.')\n",
    "    if len(out_split)<3:\n",
    "        out = web_site\n",
    "    else:\n",
    "        out = '.'.join(out_split[len(out_split)-2:])\n",
    "    if out == '':\n",
    "        out = netloc\n",
    "    return out\n",
    "def get_journal(pmid, link):\n",
    "    try:\n",
    "        if 'elsevier' in link or 'sciencedirect' in link:\n",
    "            elsevier(pmid, link)\n",
    "        elif 'springer' in link:\n",
    "            springer(pmid, link)\n",
    "        elif 'wiley' in link:\n",
    "            wiley(pmid, link)\n",
    "        elif 'acs.org' in link:\n",
    "            acs(pmid, link)\n",
    "        elif 'rsc.com' in link:\n",
    "            rsc(pmid, link)\n",
    "        elif 'tandfonline' in link:\n",
    "            tandfonline(pmid, link)\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:21: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:21: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:21: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:21: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:21: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:21: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:21: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:21: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:21: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:21: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:23: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:27: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:27: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:27: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:27: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:27: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:27: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:27: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:27: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:27: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:27: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel/__main__.py:17: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n"
     ]
    }
   ],
   "source": [
    "con = pymysql.connect(host='localhost', user='root', passwd='', db='xiaobaifinder', charset='utf8')\n",
    "cu = con.cursor()\n",
    "# cu.execute('create table if not exists journal_keyword(pmid int, keywords varchar(200))')\n",
    "# cu.execute('create table if not exists journal_aff(pmid int,aff_index int, aff_name Text)')\n",
    "# cu.execute('create table if not exists journal_author(pmid int,author_index int,\\\n",
    "#             author varchar(200), author_aff Text, email varchar(200), corresp int)')\n",
    "# cu.execute('create table if not exists journal_error(pmid int, errors Text)')\n",
    "# con.commit()\n",
    "cu_r = con.cursor()\n",
    "cu = con.cursor()\n",
    "cu_r.execute('select pmid,link from doi_link where pmid not in (select distinct pmid from journal_author)')\n",
    "# link_list = cu_r.fetchall()\n",
    "\n",
    "\n",
    "pool = multiprocessing.Pool(processes= 10) # 设置进程数\n",
    "for ii in range(cu_r.rowcount):\n",
    "    (pmid,link,) = cu_r.fetchone()\n",
    "    pool.apply_async(get_journal, (int(pmid), link,))\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "cu.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    try:\n",
    "        storage = io.BytesIO()\n",
    "        c = pycurl.Curl()\n",
    "        c.setopt(c.URL, url)\n",
    "        c.setopt(pycurl.FOLLOWLOCATION, 1) \n",
    "        c.setopt(pycurl.WRITEFUNCTION, storage.write)\n",
    "        # c.setopt(c.HTTPHEADER,[\"Accept: application/vnd.crossref.unixsd+xml\"])\n",
    "        c.perform()\n",
    "        out = c.getinfo(pycurl.EFFECTIVE_URL)\n",
    "#         cu_w.execute('insert into doi_link values(%s, %s, %s)', (pmid,doi, out))\n",
    "#         con.commit()\n",
    "        c.close()\n",
    "        content = storage.getvalue().decode('utf-8')\n",
    "#         print(out)\n",
    "#         print(content)\n",
    "        storage.close()\n",
    "        return content,out\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = pymysql.connect(host='localhost', user='root', passwd='', db='xiaobaifinder', charset='utf8')\n",
    "cu = con.cursor()\n",
    "pmid ='123'\n",
    "e='fdsd'\n",
    "cu.execute('insert into journal_error values(%s, %s)', (pmid, str(e)))\n",
    "con.commit()\n",
    "con.commit()\n",
    "cu.close()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
